{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wT3MeOQ_g79R"
      },
      "source": [
        "# Whitebox modellek: Valószínűségi hálók magyarázhatósága és értelmezése\n",
        "\n",
        "\n",
        "Készítette: &nbsp;&emsp;&emsp;Vetró Mihály \\\\\n",
        "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Dr. Gézsi András \\\\\n",
        "Elméleti anyag: &nbsp;Dr. Hullám Gábor \\\\\n",
        "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; Dr. Antal Péter \\\\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A gyakorlat célja\n",
        "\n",
        "A gyakorlat során a hallgatók egy átfogó gyakorlati példán keresztül ismerhetik meg alapszinten a valószínűségi hálók működését, a hálókban történő következtetést és annak gyakorlati alkalmazásait. <!--Ezen felül a gyakorlat kitér a Bayes-hálók kibővítéseként előállított döntési hálók alkalmazására is döntéstámogató és döntéshozó rendszerekben.-->\n"
      ],
      "metadata": {
        "id": "pOxyeU1sRT4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valószínűségszámítás alapok, feltételes valószínűség\n",
        "\n",
        "Valós mesterséges intelligencia alkalmazásokban gyakran végzünk valószínűségi következtetést, amely során valószínűségi változók értékét becsüljük meg megfigyelések illetve előzetesen ismert információk (háttértudás) alapán. A következtetés folyamán megkülönböztetjük egymástól az (1) előzetesen ismert (a priori) valószínűséget és a (2) más változók értékétől függő feltételes valószínűséget.\n",
        "\n",
        "Az előzetesen ismert valószínűség egy egyéb változóktól független értéket jelent, például egy ideális világban kockadobásnál $P(Dice=6)=\\frac{1}{6}$ (annak az esélye, hogy hatost dobunk) előzetesen ismert valószínűségnek számít.\n",
        "\n",
        "Ezzel szemben hogyha feltételezzük, hogy a kocka valamilyen valószínűséggel cinkelt lehet, akkor bevezethetünk egy új változót, amelynek értéke befolyásolja az előbb felírt valószínűség értékét. Ekkor például a $P(Dice=6|Weighted=yes)=\\frac{1}{3}$ valószínűséget **feltételes valószínűségnek**, a $Weighted=yes$ megfigyelésünket pedig **evidenciának** nevezzük.\n",
        "\n",
        "Így tehát általánosan $P(A)$-val jelöljük az $A$ valószínűségi változóhoz tartozó valószínűséget, és $P(A|B)$-vel $A$ feltételes valószínűségét $B$ evidencia ismeretében, amennyiben $A$ valószínűsége függ $B$-től.\n",
        "\n",
        "A feltételes valószínűség értékét a két változó együttes valószínűsége $P(A,B)$ és a feltétel előzetes valószínűsége $P(B)$ hányadosaként is felírhatjuk: $P(A|B)=\\frac{P(A,B)}{P(B)}$"
      ],
      "metadata": {
        "id": "klEaRRjyRRqM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Valószínűségi változók függetlensége, feltételes függetlenség\n",
        "\n",
        "Két valószínűségi változó **független** egymástól, amennyiben mindkettőre igaz, hogy lehetséges értékeinek valószínűsége állandó marad a másik értékének ismeretében, bármilyen értéket is vegyen az föl. Például ugyanakkora valószínűséggel dobunk hatost akkor is, ha felhős idő van, és akkor is, ha napos. Általánosan $A$ és $B$ független valószínűségi változók mellett mindig igaz, hogy\n",
        "\n",
        "$P(A|B)=P(A)$, \\\\\n",
        "$P(B|A)=P(B)$ és  \n",
        "$P(A,B)=P(A)P(B)$.\n",
        "\n",
        "Amennyiben ezek bármelyike nem teljesül, akkor a valószínűségi változók **összefüggőek**.\n",
        "\n",
        "<!-- Esetünkben a valószínűségi következtetés során valamilyen esemény valószínűsége alatt annak az éppen ismert evidenciák melletti valószínűségét értjük. Így tehát két változó akkor összefüggő, hogyha valamelyikük egy adott értékének evidenciaként való bevezetése megváltoztatja a másik valószínűségét. -->\n",
        "\n",
        "Előfordulhat olyan eset is, amikor egy változó ismerete egy másik változó értékét irrelevánssá teszi a vizsgált valószínűségi változó eloszlására való tekintettel.\n",
        "\n",
        ">Például tegyük fel, hogy egy játékban veszünk részt, ahol bizonyos valószínűséggel lebukhatunk, ha cinkelt kockát használunk. Ekkor ha nem ismert, hogy a kocka cinkelt-e, akkor a kockadobás eredménye hatással van arra, hogy lebukunk-e, mert megnövelheti (vagy csökkentheti) a cinkelt kocka használatának valószínűségét. Viszont hogyha (minden szereplő előtt) ismert, hogy a kocka nem cinkelt, akkor bármennyit is dobunk, nem fogunk lebukni, ugyanis nem követtünk el csalást. Ekkor azt mondjuk, hogy a $Weighted$ változó értékének ismeretében a $Caught$ (lebukás) változó független a $Dice$ változótól.\n",
        "\n",
        "Általánosan, ha $B$ változó $C$ változó ismeretében nem szolgál plusz információval $A$ változó eloszlásáról, vagyis $P(A|B,C)=P(A|C)$ teljesül, akkor azt mondjuk, hogy $A$ és $B$ változók **feltételesen függetlenek** $C$ ismeretében. Formálisan erre az $I(A,B|C)$ jelölést használjuk.\n",
        "\n",
        ">Az előző példára vetítve ez azt jelenti, hogy $P(Caught|Weighted,Dice)=P(Caught|Weighted)$, tehát $I(Caught,Dice|Weighted)$."
      ],
      "metadata": {
        "id": "FIM4sIW2ROHu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Bayes-tétel és alkalmazása\n",
        "\n",
        "Két valószínűségi változó együttes valószínűségét a feltételes valószínűség definiciója alapján az alábbi módon is felírhatjuk: $P(A,B)=P(A|B)P(B)$. Tehát $A$ feltétles valószínűsége $B$ ismeretében szorozva $B$ valószínűségével.\n",
        "Hasonlóképpen $P(B,A)=P(B|A)P(A)$.\n",
        "\n",
        "Mivel az együttes valószínűségben a változók lehetséges értékei között fennálló ÉS kapcsolat kommutatív, vagyis $P(A,B)=P(B,A)$, ezért $P(A|B)P(B)=P(B|A)P(A)$.\n",
        "Ekkor a $P(B)$-vel való osztás után az alábbi egyenlőséget kapjuk:\n",
        "\n",
        "$$P(A|B)=\\frac{P(B|A)P(A)}{P(B)}$$\n",
        "\n",
        "\n",
        "Ezt az azonosságot felfedezője után **Bayes-tétel**nek nevezzük, és nagy jelentőséggel bír a valószínűségi következtetésben. Sokszor ugyanis az a célunk, hogy a rendelkezésre álló $D$ adat alapján tudjunk következtetést levonni a háttérben lévő $M$ modellről, amit nem ismerünk $P(M|D)$, és ez így kihívást jelent. Jóval egyszerűbb egy ismert modellt feltételezve meghatározni a megfigyelt adat feltételes valószínűségét ($P(D|M)$), amit **likelihoodnak** nevezünk. A Bayes-tétel tehát lehetővé teszi, hogy a megfigyeléseket követő, vagy más néven **a posteriori** valószínűséget ($P(M|D)$) kiszámítsuk a likelihood ($P(D|M)$) alapján:\n",
        "\n",
        "$$P(M|D)=\\frac{P(D|M)P(M)}{P(D)}$$\n",
        "\n",
        "Ebben a kontextusban a $P(M)$ kifejezést előzetesen ismert, vagy más néven **a priori** valószínűségnek nevezzük, a $P(D)$ kifejezést pedig normalizációs konstansnak tekintjük és gyakran elhanyagoljuk.\n",
        "\n",
        "\n",
        ">A Bayes-tételt alkalmazva például a kockadobás esetén a dobott érték, és a két változó előzetes valószínűsége alapján meg tudjuk határozni annak a valószínűségét, hogy a kocka cinkelt, amennyiben hatost dobtunk:\n",
        "$$P(Weighted=true|Dice=6)=\\frac{P(Dice=6|Weighted=true)P(Weighted=true)}{P(Dice=6)}$$\n",
        "Ekkor a $P(Weighted=true)$ valószínűséget előzetesen ismert, vagy **a priori** valószínűségnek, $P(Dice=6|Weighted=true)$ valószínűséget **likelihoodnak**, a $P(Weighted=true|Dice=6)$ valószínűséget pedig megfigyelés utáni, vagyis **a posteriori** valószínűségnek nevezzük."
      ],
      "metadata": {
        "id": "11JM9SNMRIHW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Likelihood\" versus \"a posteriori valószínűség\"\n",
        "\n",
        "Következtetésnél fontos megkülönböztetni az *a posteriori valószínűség* és a *likelihood* fogalmát.\n",
        "\n",
        "**Likelihood** alatt azt értjük, amikor ismerjük (vagy legalábbis feltételezzük) a változó eloszlását, és azt szeretnénk tudni, hogy egy konkrét értéke (vagy folytonos esetben egy adott tartományba eső érték) mekkora valószínűséggel fordul elő. Ez a kockadobásnál annak felel meg, hogy már van valamilyen feltételezésünk arról, hogy a kocka cinkelt-e, és tudni szeretnénk, hogy ha ezen feltételezésünk igaz, akkor mekkora eséllyel dobunk hatost. Konkrétabban $P(Dice|Weighted)$ értékére vagyunk kíváncsiak ebben az esetben.\n",
        "\n",
        "**A posteriori valószínűség** esetén ezzel szemben arra vagyunk kíváncsiak, hogy adott megfigyelés esetén mekkora a valószínűsége annak, hogy azt egy adott eloszlásból kaptuk. Kockadobás esetén ez azt jelenti, hogy tudjuk a kockadobás eredményét, és azt szeretnénk tudni, hogy így mekkora a valószínűsége annak, hogy a kocka cinkelt. Így tehát ezen analógia mentén a $P(Weighted|Dice)$ érték a posteriori valószínűségnek számít."
      ],
      "metadata": {
        "id": "31-AyD1NRENC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A valószínűségi hálók\n",
        "\n",
        "Az előző bekezdésben beláttuk, hogy két változó együttes valószínűségét fel lehet bontani az alábbi módon: $P(A,B)=P(A|B)P(B)$. Ezen felbontás tetszőleges számú változóra történő általánosítását **lánc-szabálynak** nevezzük, amely $n$ darab változóra az alábbi módon alkalmazható:\n",
        "\n",
        "$$P(X_1,X_2,...,X_n)=P(X_n|X_{n-1},X_{n-2},...,X_1)P(X_{n-1}|X_{n-2},X_{n-3},...,X_1)...P(X_2|X_1)P(X_1)$$\n",
        "\n",
        "Vagy rövidebben:\n",
        "\n",
        "$$P(X_1,X_2,...,X_n)=\\prod_{i=1}^{n}P(X_i|X_{i-1},...,X_1)$$\n",
        "\n",
        "<!-- >Amennyiben a modellünk változói között vannak egymástól (feltételesen) független változók (amely gyakorlati alkalmazásokban általában igaz), akkor egy ennél (akár jelentősen) rövidebb, vagyis kevesebb feltételt tartalmazó felbontás is elegendő a modell együttes valószínűségének felírásához. Például egy $A$, $B$, $C$ és $D$ valószínűségi változókat tartalmazó modell együttes valószínűsége alapvetően az alábbi módon bontható fel:\n",
        "$$P(A,B,C,D)=P(A|B,C,D)P(B|C,D)P(C|D)P(D)$$\n",
        "Azonban hogyha $A$, $B$ és $C$ változók $D$ ismeretében feltételesen függetlenek, tehát $I(A,B,C|D)$ teljesül, akkor a felbontás jelentősen egyszerűbben is elvégezhető:\n",
        "$$P(A,B,C,D)=P(A|D)P(B|D)P(C|D)P(D)$$\n",
        "Gyakorlati alkalmazásokban ez általában azt jelenti, hogy $D$ valószínűségi változó értéke *közvetlenül befolyásolja* a modell másik három változójának valószínűségét.-->\n",
        "\n",
        "Egy modell változóinak együttes valószínűsége ilyen ábrázolásban viszonylag nehezen átlátható, főleg nagyobb méretű modellek esetén. Ebből adódóan érdemes valamilyen grafikus reprezentációt bevezetnünk, amely könnyebben értelmezhető formában mutatja be a modell változói között fennálló kapcsolatokat. Először is feltételezzük, hogy a modell minden $A$ változójára létezik egy olyan $Parents(A)$ változóhalmaz, amely halmazok esetén az alábbi felbontás (faktorizáció) érvényes felbontása lesz a modell együttes valószínűségének, $n$ darab változót tartalmazó modell esetén:\n",
        "\n",
        "$$P(X_1,X_2,...,X_n)=\\prod_{i=1}^nP(X_i|Parents(X_i))$$\n",
        "\n",
        "Ekkor a $Parents(A)$ halmaz elemeit $A$ változó **szüleinek**, azon $X$ változókat pedig, amelyekre a $A \\in Parents(X)$ pedig $A$ **gyerekeinek** nevezzük (az adott felbontás szerint).\n",
        "\n",
        "\n",
        "**Bayes-háló (Definíció)**: Azt a körmentes irányított gráfot (Directed Acyclic Graph - DAG), amelynek csomópontjai a modellben található valószínűségi változók, élei pedig a változók közötti függőségi (szülő-gyerek) kapcsolatot reprezentálják úgy, hogy az él a szülőből kiindulva annak gyerekébe mutat, **valószínűségi hálónak** vagy **Bayes-hálónak** nevezzük, ha minden csomóponthoz tartozik egy feltétles valószínűségi eloszlás, amely a szülők értékei függvényében határozza meg a csomópont által reprezentált valószínűségi változó eloszlását.\n",
        "\n",
        ">Például a kockadobás esetén $I(Caught,Dice|Weighted)$ feltételes függetlenség miatt érvényes az alábbi felbontás: $P(Caught,Dice,Weighted)=P(Caught|Weighted)P(Dice|Weighted)P(Weighted)$.\n",
        "\n",
        ">Eszerint a felbontás szerint $Parents(Caught)=\\{Weighted\\}$, $Parents(Dice)=\\{Weighted\\}$ és $Parents(Weighted)=\\{\\}$, így tehát a modell ezen felbontáshoz tartozó Bayes-háló struktúrája a hozzá tartozó **feltételes valószínűségi táblázattal** együtt az alábbi:\n",
        "\n",
        "<center><img src=\"https://i.ibb.co/09Gd9P2/Weighted-Dice.png\" width=\"350\"></center>\n",
        "\n",
        "| $Weighted$ | $P(Weighted)$ | \\| | $Dice$ | $Weighted$ | $P(Dice|Weighted)$ | \\| | $Caught$ | $Weighted$ | $P(Caught|Weighted)$ |\n",
        "|:----------:|:-------------:|:--:|:------:|:----------:|:------------------:|:--:|:--------:|:----------:|:--------------------:|\n",
        "| $true$ | $0.1$ | \\| | $1$ | $false$ | $1/6$ | \\| | $false$ | $false$ | $1$ |\n",
        "| $false$ | $0.9$ | \\| | $2$ | $false$ | $1/6$ | \\| | $true$ | $false$ | $0$ |\n",
        "|  |  | \\| | $3$ | $false$ | $1/6$ | \\| | $false$ | $true$ | $0.7$ |\n",
        "|  |  | \\| | $4$ | $false$ | $1/6$ | \\| | $true$ | $true$ | $0.3$ |\n",
        "|  |  | \\| | $5$ | $false$ | $1/6$ | \\| |  |  |  |\n",
        "|  |  | \\| | $6$ | $false$ | $1/6$ | \\| |  |  |  |\n",
        "|  |  | \\| | $1$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $2$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $3$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $4$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $5$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $6$ | $true$ | $1/3$ | \\| |  |  |  |\n",
        "\n",
        ">Ebben az esetben a feltételes valószínűségi táblázat azzal ekvivalens, mintha felírtuk volna az egyes feltételes valószínűséggel rendelkező valószínűségi változók összes lehetséges értékének valószínűségét a feltételként fennálló változók összes lehetséges értékkombinációja mellett."
      ],
      "metadata": {
        "id": "mIbUGIccQ_Tq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Következtetés Bayes-hálókban\n",
        "\n",
        "Valószínűségi modellek esetén következtetés alatt azt értjük, hogy egy adott változóhalmaz (evidencia) értékének ismeretében kiszámítjuk az ismeretlen értékű valószínűségi változók egy részhalmazának együttes valószínűségét. A következtetés talán legegyszerűbb módja az úgynevezett **felsorolásos egzakt következtetés**.\n",
        "\n",
        "\n",
        "\n",
        "<!--   Ennek során adott evidenciahalmaz mellett összegezzük az ismeretlen változók lehetséges érték-kombinációinak valószínűségét, amelyből meghatározzuk a keresett együttes valószínűséget. Legyen $\\boldsymbol{X}$ az (ismeretlen értékű) célváltozóink halmaza, $\\boldsymbol{e}$ az ismert evidenciák értéke, $\\boldsymbol{Y}$ pedig az összes többi változót tartalmazó halmaz. Ekkor a keresett $\\boldsymbol{X}$ változóhalmaz együttes valószínűségét felírhatjuk az alábbi módon, $\\boldsymbol{Y}$ változóhalmaz lehetséges értékei fölött összegezve:   \n",
        "\n",
        "$$P(\\boldsymbol{X}|\\boldsymbol{e}) = \\alpha P(\\boldsymbol{X},\\boldsymbol{e}) = \\alpha \\sum_{\\boldsymbol{y} \\in \\boldsymbol{Y}}P(\\boldsymbol{X}, \\boldsymbol{e}, \\boldsymbol{y})$$\n",
        "\n",
        "ahol $\\alpha$ az úgynevezett normalizációs tényező, amely értékét úgy kell megválasztani, hogy az összes lehetséges (és természetesen nemnegatív) együttes valószínűség értékének összege $1$ legyen.\n",
        "\n",
        "A következtetés szemléltetése értekében vegyük elő újból a kockadobás példáját. Tegyük fel, hogy a kocka 10% eséllyel cinkelt, a cinkelt kocka megduplázza annak valószínűségét, hogy hatost dobunk, és csalás (tehát cinkelt kocka) esetén 30% eséllyel bukunk le. Ekkor a modell változóinak valószínűségei az alábbiak:\n",
        "\n",
        "$$P(Weighted=true)=0.1$$\n",
        "$$P(Weighted=false)=0.9$$\n",
        "$$P(Dice=1|Weighted=false)=1/6$$\n",
        "$$P(Dice=2|Weighted=false)=1/6$$\n",
        "$$P(Dice=3|Weighted=false)=1/6$$\n",
        "$$P(Dice=4|Weighted=false)=1/6$$\n",
        "$$P(Dice=5|Weighted=false)=1/6$$\n",
        "$$P(Dice=6|Weighted=false)=1/6$$\n",
        "$$P(Dice=1|Weighted=true)=2/15$$\n",
        "$$P(Dice=2|Weighted=true)=2/15$$\n",
        "$$P(Dice=3|Weighted=true)=2/15$$\n",
        "$$P(Dice=4|Weighted=true)=2/15$$\n",
        "$$P(Dice=5|Weighted=true)=2/15$$\n",
        "$$P(Dice=6|Weighted=true)=1/3$$\n",
        "$$P(Caught=false|Weighted=false)=1$$\n",
        "$$P(Caught=true|Weighted=false)=0$$\n",
        "$$P(Caught=false|Weighted=true)=0.7$$\n",
        "$$P(Caught=true|Weighted=true)=0.3$$\n",
        "\n",
        "Már elkezdtük a játékot, és dobtunk egy hatost, viszont nem tudjuk hogy a kocka cinkelt-e. Azt viszont szeretnénk tudni, hogy mekkora eséllyel bukunk le, a játékból ugyanis akkor is kizárnak bennünket, hogyha csaltunk, de nem tudtunk róla. Ekkor evicenciaként egyetlen változó-értékünk van: $\\boldsymbol{e}=\\{Dice=6\\}$, és a célváltozóink halmaza is egyetlen elemből áll: $\\boldsymbol{X}=\\{Caught\\}$. Az $Y$ halmaz ekkor az egyetlen, eddig említett halmazba sem tartozó változót tartalmazza: $\\boldsymbol{Y}=\\{Weighted\\}$. Ezeket helyettesítsük be a fenti képletbe:\n",
        "\n",
        "$$P(Caught|Dice=6)=\\alpha P(Caught,Dice=6)=\\alpha (P(Caught,Dice=6,Weighted=true) + P(Caught,Dice=6,Weighted=false))$$\n",
        "\n",
        "A \"Valószínűségi hálók\" bekezdésben említett módszer segítségével a modell változóinak együttes valószínűségét felbonthatjuk az alábbi módon:\n",
        "\n",
        "$$P(Caught,Dice,Weighted)=P(Caught|Weighted)P(Dice|Weighted)P(Weighted)$$\n",
        "\n",
        "Amely felbontás segítségével kiszámíthatjuk a lebukás valószínűségét, a fenti értékek behelyettesítése után:\n",
        "\n",
        "$$P(Caught=true|Dice=6)=\\alpha (P(Caught=true,Dice=6,Weighted=true) + P(Caught=true,Dice=6,Weighted=false))=$$\n",
        "\n",
        "$$=\\alpha (P(Caught=true|Weighted=true)P(Dice=6|Weighted=true)P(Weighted=true) + P(Caught=true|Weighted=false)P(Dice=6|Weighted=false)P(Weighted=false))=$$\n",
        "\n",
        "$$=\\alpha (0.3 \\cdot \\frac{1}{3} \\cdot 0.1 + 0 \\cdot \\frac{1}{6} \\cdot 0.9) = 0.01\\alpha$$\n",
        "\n",
        "$\\alpha$ értékének meghatározásához ki kell számítanunk $Caught=false$-hoz tartozó értéket is:\n",
        "\n",
        "$$P(Caught=false|Dice=6)=\\alpha (P(Caught=false,Dice=6,Weighted=true) + P(Caught=false,Dice=6,Weighted=false))=$$\n",
        "\n",
        "$$=\\alpha (P(Caught=false|Weighted=true)P(Dice=6|Weighted=true)P(Weighted=true) + P(Caught=false|Weighted=false)P(Dice=6|Weighted=false)P(Weighted=false))=$$\n",
        "\n",
        "$$=\\alpha (0.7 \\cdot \\frac{1}{3} \\cdot 0.1 + 1 \\cdot \\frac{1}{6} \\cdot 0.9) = 0.17\\dot 3\\alpha$$\n",
        "\n",
        "Ezekből az $\\alpha$ értéke:\n",
        "\n",
        "$$0.01\\alpha + 0.17\\dot 3\\alpha = 1$$\n",
        "$$\\alpha = 5.\\dot 4 \\dot 5$$\n",
        "\n",
        "Végül pedig a valószínűség:\n",
        "\n",
        "$$P(Caught=true|Dice=6)=0.01\\alpha=0.0\\dot 5\\dot 4 \\approx 0.055$$\n",
        "$$P(Caught=false|Dice=6)=0.17\\dot 3\\alpha=0.9\\dot 4 \\dot 5 \\approx 0.945$$\n",
        "\n",
        "amelyre az $\\alpha = 5.\\dot 4 \\dot 5$ választásnak köszönhetően teljesül, hogy\n",
        "\n",
        "$$P(Caught=true|Dice=6)+P(Caught=false|Dice=6)=1$$\n",
        "\n",
        "Az előzőek fényében szembetűnő, hogy a feltételes valószínűségek egyenként történő felsorolása egy nem kifejezetten átlátható felírást eredményez. Egy ennél átláthatóbb módszert kínál az úgynevezett feltételes valószínűségi tábla, amely a kockadobásra felírt valószínűségek esetén az alábbi:\n",
        "\n",
        "| $Weighted$ | $P(Weighted)$ | \\| | $Dice$ | $Weighted$ | $P(Dice|Weighted)$ | \\| | $Caught$ | $Weighted$ | $P(Caught|Weighted)$ |\n",
        "|:----------:|:-------------:|:--:|:------:|:----------:|:------------------:|:--:|:--------:|:----------:|:--------------------:|\n",
        "| $true$ | $0.1$ | \\| | $1$ | $false$ | $1/6$ | \\| | $false$ | $false$ | $1$ |\n",
        "| $false$ | $0.9$ | \\| | $2$ | $false$ | $1/6$ | \\| | $true$ | $false$ | $0$ |\n",
        "|  |  | \\| | $3$ | $false$ | $1/6$ | \\| | $false$ | $true$ | $0.7$ |\n",
        "|  |  | \\| | $4$ | $false$ | $1/6$ | \\| | $true$ | $true$ | $0.3$ |\n",
        "|  |  | \\| | $5$ | $false$ | $1/6$ | \\| |  |  |  |\n",
        "|  |  | \\| | $6$ | $false$ | $1/6$ | \\| |  |  |  |\n",
        "|  |  | \\| | $1$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $2$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $3$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $4$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $5$ | $true$ | $2/15$ | \\| |  |  |  |\n",
        "|  |  | \\| | $6$ | $true$ | $1/3$ | \\| |  |  |  |\n",
        "\n",
        "Végül fontos kiemelni, hogy a felsorolásos egzakt következtetés komplexitása többszörösen összekötött hálók (olyan hálók, amelyeknek van két, egynél több irányított úttal összekötött csomópontja) esetén a csomópontok számára exponenciális, így nagyobb hálók esetén nem praktikus a használata. Ennek kiküszöbölésére léteznek egyéb, egzakt következtetést megvalósító, de hatékonyabb algoritmusok, illetve közelítő (tehát nem egzakt) következtetést megvalósító algoritmusok is.-->\n",
        "\n",
        "Továbbá léteznek egzakt következtetést megvalósító, de hatékonyabb algoritmusok, illetve közelítő (tehát nem egzakt) következtetést megvalósító algoritmusok is.\n",
        "Ezek részletes leírása megtalálható: Stuart Russell és Peter Norvig Mesterséges Intelligencia - Modern megközelítésben című könyvének [14.4.](https://mialmanach.mit.bme.hu/aima/ch14s04) és [14.5.](https://mialmanach.mit.bme.hu/aima/ch14s05) fejezetében."
      ],
      "metadata": {
        "id": "8qyWQ6x8Q2H8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NO6O3VzgoSy2"
      },
      "source": [
        "---\n",
        "\n",
        "# A feladat előkészítése\n",
        "\n",
        "## A keretrendszer\n",
        "\n",
        "A gyakorlat során feltételezzük a Python nyelv, és a Google Colab környezet alapszintű ismeretét. Ezeken felül lényegében két eszközt fogunk használni: a pgmpy python könyvtárat a valószínűségi hálók implementációjához, illetve az ez által használt pygraphviz könyvtárat a megalkotott hálók vizualizációjához.\n",
        "\n",
        "Ezek telepítéséhez futtassa le az alábbi kódblokkot (a telepítés több percet is igénybe vehet):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUIRK-HzMd6f"
      },
      "source": [
        "%%capture\n",
        "!pip install pgmpy==0.1.24\n",
        "!apt-get install -y graphviz-dev\n",
        "!pip install pygraphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRP4MRm42njN"
      },
      "source": [
        "Várja meg, amíg a telepítés befejeződik, majd importálja a kezdetben szükséges könyvtárakat az alábbi kódblokk lefuttatásával:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05eIkkv6NxB7"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib as mpl\n",
        "# Just so the generated figures won't look too ugly\n",
        "mpl.rcParams['figure.figsize'] = [3, 2]\n",
        "mpl.rcParams['figure.dpi'] = 200\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import pgmpy as pg; print('pg: ' + pg.__version__)\n",
        "import numpy as np; print('np: ' + np.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vp_JzjbA-iQg"
      },
      "source": [
        "Amennyiben a telepítés során, vagy a későbbiekben hibát észlel, vagy bármilyen egyéb kérdése van, forduljon bátran a gyakorlatvezetőhöz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4UNXsK7-LAj"
      },
      "source": [
        "## A modell bemutatása\n",
        "\n",
        "A modern autóiparban egyre gyakrabban alkalmaznak vezetői fáradtságot detektáló rendszereket. A gyakorlat során egy ilyen rendszer implementálása által fogjuk megismerni a Bayes-hálón alapuló valószínűségi következtető rendszerek működését. A változók tekintetében az egyszerűség kedvéért feltételezzük, hogy a rendszer már előzetesen feldolgozott, magas szintű információt kap, így a bemenetek mindegyike diszkrét, többségük bináris.\n",
        "\n",
        "A modellben bevezetendő valószínűségi változók az alábbiak:\n",
        "\n",
        "*   Az út hossza (**LengthOfDrive**): Bináris változó, értéke *long*, hogyha a vezető által egyhuzamban megtett út hossza egy adott határértéknél magasabb. Ellenkező esetben *short*.\n",
        "*   Forgalmi dugó (**TrafficJam**): Értéke *jammed*, hogyha az út során a sofőr jelentős dugóba kerül. Ellenkező esetben *clear*.\n",
        "*   Szívverés (**HeartRate**): Értéke *low*, hogyha a sofőr pulzusa az alvás során jellemző tartományban van. Ellenkező esetben *normal*.\n",
        " *  A pulzus mérhető például egy, a kormánykeréken elhelyezett szenzor segítségével.\n",
        "*   Sávtartás (**LaneStability**): Attól függően, hogy a sofőr tartja a sávot, enyhén instabilan vezet, vagy éppen elhagyja a sávot, az értéke lehet *straight*, *slalom* vagy *leaving*.\n",
        "*   Szemek (**Eyes**): Értéke lehet *open*, *blink* vagy *closed* attól függően, hogy a sofőr szeme folyamatosan nyitva van, gyakran pislog, vagy teljesen csukva van.\n",
        " *  A szemek viselkedése egy, a sofőrrel szemben elhelyezett kamera képéből kinyerhető valamilyen képfeldolgozó modell segítségével.\n",
        "*   Fáradtság (**Fatigue**): Értéke *fatigued*, hogyha a vezető fáradtsága annyira magas, hogy nagy valószínűséggel elalszik a volánnál. Ellenkező esetben kipihent, vagyis *rested*.\n",
        "\n",
        "A továbbakban a kompaktság érdekében a képletek esetén az alábbi jelölést alkalmazzuk a változókra:\n",
        "\n",
        "| Változó neve | Jelölés |\n",
        "| :---: | :---: |\n",
        "| **LengthOfDrive** | $LOD$ |\n",
        "| **TrafficJam** | $TJ$ |\n",
        "| **HeartRate** | $HR$ |\n",
        "| **LaneStability** | $LS$ |\n",
        "| **Eyes** | $E$ |\n",
        "| **Fatigue** | $F$ |\n",
        "\n",
        "Könnyen belátható, hogy az első két változó (**LengthOfDrive**, **TrafficJam**) a fáradtságnak (**Fatigue**) okai, az utánuk következő három (**HeartRate**,**LaneStability**, **Eyes**) pedig következményei. Belátható az is, hogy a sávtartást a fáradtság mellett befolyásolja a szemek állapota is. Ebből adódóan a változók együttes valószínűsége felírható az alábbi módon:\n",
        "\n",
        "$$P(LOD,TJ,HR,LS,E,F)=P(LOD)P(TJ)P(F|LOD,TJ)P(HR|F)P(LS|F,E)P(E|F)$$\n",
        "\n",
        "A változók valószínűségi eloszlását pedig az alábbi **feltételes valószínűségi táblázat**ok adják meg:\n",
        "\n",
        "|  $LOD$  \t| $P(LOD)$ \t| \\| \t|   $TJ$  \t| $P(TJ)$ \t| \\| \t|  $LOD$  \t|   $TJ$  \t|   $F$   \t| $P(F|LOD,TJ)$ \t| \\| \t|   $F$   \t|  $HR$  \t| $P(HR|F)$ \t| \\| \t|   $F$   \t|    $E$   \t|    $LS$    \t| $P(LS|F,E)$ \t| \\| \t|   $F$   \t|    $E$   \t| $P(E|F)$ \t|\n",
        "|:-------:\t|:--------:\t|:--:\t|:-------:\t|:-------:\t|:--:\t|:-------:\t|:-------:\t|:-------:\t|:-------------:\t|:--:\t|:-------:\t|:-------:\t|:----------:\t|:--:\t|:-------:\t|:--------:\t|:----------:\t|:---------:\t|:--:\t|:-------:\t|:--------:\t|:--------:\t|\n",
        "| $long$  \t|   $0.1$  \t| \\| \t| $jammed$  \t| $0.3$   \t| \\| \t| $long$  \t| $jammed$  \t| $fatigued$  \t| $0.65$        \t| \\| \t| $fatigued$  \t| $low$  \t| $0.8$      \t| \\| \t| $fatigued$  \t| $open$   \t| $straight$ \t| $0.89$    \t| \\| \t| $fatigued$  \t| $open$   \t| $0.1$    \t|\n",
        "| $short$ \t|   $0.9$  \t| \\| \t| $clear$ \t| $0.7$   \t| \\| \t| $long$  \t| $jammed$  \t| $rested$ \t| $0.35$        \t| \\| \t| $fatigued$  \t| $normal$ \t| $0.2$      \t| \\| \t| $fatigued$  \t| $open$   \t| $slalom$   \t| $0.1$     \t| \\| \t| $fatigued$  \t| $blink$  \t| $0.85$   \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $long$  \t| $clear$ \t| $fatigued$  \t| $0.45$        \t| \\| \t| $rested$ \t| $low$  \t| $0.3$      \t| \\| \t| $fatigued$  \t| $open$   \t| $leaving$  \t| $0.01$   \t| \\| \t| $fatigued$  \t| $closed$ \t| $0.05$   \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $long$  \t| $clear$ \t| $rested$ \t| $0.55$        \t| \\| \t| $rested$ \t| $normal$ \t| $0.7$      \t| \\| \t| $fatigued$ \t| $blink$   \t| $straight$ \t| $0.7$       \t| \\| \t| $rested$ \t| $open$   \t| $0.94$   \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $short$ \t| $jammed$  \t| $fatigued$  \t| $0.55$        \t| \\| \t|         \t|         \t|            \t| \\| \t| $fatigued$ \t| $blink$   \t| $slalom$   \t| $0.2$\t        | \\| \t| $rested$ \t| $blink$  \t| $0.05$   \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $short$ \t| $jammed$  \t| $rested$ \t| $0.45$        \t| \\| \t|         \t|         \t|            \t| \\| \t| $fatigued$ \t| $blink$   \t| $leaving$  \t| $0.1$      \t| \\| \t| $rested$ \t| $closed$ \t| $0.01$   \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $short$ \t| $clear$ \t| $fatigued$  \t| $0.35$        \t| \\| \t|         \t|         \t|            \t| \\| \t| $fatigued$   \t| $closed$  \t| $straight$  \t| $0.5$        \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| $short$ \t| $clear$ \t| $rested$ \t| $0.65$        \t| \\| \t|         \t|         \t|            \t| \\| \t| $fatigued$    | $closed$  \t| $slalom$ \t| $0.3$        \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $fatigued$    | $closed$  \t| $leaving$   \t| $0.2$        \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $open$  \t| $straight$ \t| $0.99$      \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $open$  \t| $slalom$ \t| $0.009$     \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $open$  \t| $leaving$   \t| $0.001$      \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $blink$  \t| $straight$ \t| $0.86$       \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $blink$  \t| $slalom$ \t| $0.13$       \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $blink$  \t| $leaving$   \t| $0.01$       \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $closed$  \t| $straight$ \t| $0.8$       \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $closed$  \t| $slalom$ \t| $0.15$       \t| \\| \t|         \t|          \t|          \t|\n",
        "|         \t|          \t| \\| \t|         \t|         \t| \\| \t| \t \t| \t \t| \t \t| \t        \t| \\| \t|         \t|         \t|            \t| \\| \t| $rested$      | $closed$  \t| $leaving$  \t| $0.05$       \t| \\| \t|         \t|          \t|          \t|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sh-ccsla1Hl"
      },
      "source": [
        "## A modell implementációja\n",
        "\n",
        "Kezdetben hozzunk létre egy Bayes-hálót a **LengthOfDrive**, **TrafficJam**, **Fatigue** és **HeartRate** változókból. Ehhez először inicializálja a változók eloszlásait (feltételes valószínűségi táblák, azaz `TabularCPD`-k formájában) az alábbi kódblokk lefuttatásával:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y_g_YvHbF6N"
      },
      "source": [
        "from pgmpy.factors.discrete import TabularCPD\n",
        "\n",
        "lengthOfDrive = TabularCPD(\"LengthOfDrive\", 2, [[0.1], [0.9]],\n",
        "                           state_names={\"LengthOfDrive\": [\"long\", \"short\"]})\n",
        "\n",
        "trafficJam = TabularCPD(\"TrafficJam\", 2, [[0.3], [0.7]],\n",
        "                        state_names={\"TrafficJam\": [\"jammed\", \"clear\"]})\n",
        "\n",
        "fatigue = TabularCPD(\"Fatigue\", 2, [[0.65, 0.45, 0.55, 0.35],\n",
        "                                    [0.35, 0.55, 0.45, 0.65]],\n",
        "                     evidence=[\"LengthOfDrive\", \"TrafficJam\"],\n",
        "                     evidence_card=[2, 2],\n",
        "                     state_names={\n",
        "                         \"Fatigue\": [\"fatigued\", \"rested\"],\n",
        "                         \"LengthOfDrive\": [\"long\", \"short\"],\n",
        "                         \"TrafficJam\": [\"jammed\", \"clear\"]\n",
        "                     })\n",
        "\n",
        "heartRate = TabularCPD(\"HeartRate\", 2, [[0.8, 0.3],\n",
        "                                        [0.2, 0.7]],\n",
        "                       evidence=[\"Fatigue\"],\n",
        "                       evidence_card=[2],\n",
        "                       state_names={\n",
        "                           \"HeartRate\": [\"low\", \"normal\"],\n",
        "                           \"Fatigue\": [\"fatigued\", \"rested\"]\n",
        "                       })"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm3Hxy3VDk-n"
      },
      "source": [
        "Mint látható, a pgmpy könyvtárban az önálló eloszlások (a kódban `TabularCPD`) meghatározása során a feltételes valószínűségeket mátrixos formában kell megadni, ahol a mátrix oszlopai a szülőváltozó(k) érték-kombinációinak, sorai pedig az adott változó a bemeneti értékkombináció függvényében vett eloszlását (értékeinek valószínűségeit) adják. Evidens, hogy utóbbi ok miatt minden oszlop összege pontosan $1$ kell, hogy legyen. Ezen kívül a változó meghatározásához meg kell adni annak nevét, kardinalitását és lehetséges értékeit, illetve minden szülője esetében meg kell adni ugyanezt. További információ és példák a pgmpy [dokumentációjában](https://pgmpy.org/factors/discrete.html#module-pgmpy.factors.discrete.CPD) láthatók."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-3Ji1EKJK6E"
      },
      "source": [
        "A változók és azok eloszlásainak definiálását követően példányosítsunk egy hálót, majd adjuk hozzá a változók eloszlásait tartalmazó CPD-ket:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VimB7wyuJ6b_"
      },
      "source": [
        "from pgmpy.models import BayesianNetwork\n",
        "\n",
        "# Initialize a new Bayesian network\n",
        "partialModel = BayesianNetwork([(\"LengthOfDrive\", \"Fatigue\"),\n",
        "                                (\"TrafficJam\", \"Fatigue\"),\n",
        "                                (\"Fatigue\", \"HeartRate\")])\n",
        "\n",
        "# Add the previously defined conditional probability tables to the model\n",
        "partialModel.add_cpds(lengthOfDrive, trafficJam, fatigue, heartRate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIM-gy3YMDJT"
      },
      "source": [
        "Az így elkészült modell struktúráját gráf formájában kirajzolhatjuk az alább definiált, `pygraphviz` könyvtárra épülő `plot_model` függvény segítségével:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.base import DAG\n",
        "import tempfile\n",
        "\n",
        "def plot_model(model: DAG):\n",
        "  model_gvz = model.to_graphviz()\n",
        "  with tempfile.NamedTemporaryFile() as tf:\n",
        "    model_gvz.draw(tf.name, format='png', prog='dot')\n",
        "    img = mpl.image.imread(tf.name)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "FF9x5ZAdWAz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(partialModel)"
      ],
      "metadata": {
        "id": "yMT2valfOHSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDN4kq3FOYCK"
      },
      "source": [
        "# Gyakorlati feladatok\n",
        "\n",
        "## 1. feladat: A modell kiegészítése\n",
        "&#x1F4DD; Egészítse ki az alábbi kódot úgy, hogy a modell tartalmazza a **LaneStability** és **Eyes** valószínűségi változókat is, a modell bemutatásában szereplő elnevezési konvenciónak és feltételes valószínűségeknek megfelelően, majd futtassa le az elkészült kódblokkot:\n",
        "\n",
        "> Itt fontos megfigyelni, hogy a létrehozandó változóknak $3$ lehetséges értéke van (Tehát 'straight', 'slalom' és 'leaving' értékek a **LaneStability** változónál, illetve 'open', 'blink', 'closed' értékek az **Eyes** esetén), emiatt a feltételes valószínűségeket leíró mátrixok **három sort tartalmaznak** az eddigi változóknál látott kettő sor helyett.\n",
        "\n",
        "**Fontos:** A két változó eloszlásának az arra kijelölt helyen történő meghatározásán felül **egyéb változtatást ne hajtson végre a már meglévő kódon!**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwmZod8dPsLz"
      },
      "source": [
        "# TASK: Define the ConditionalProbabilityTables 'laneStability' and 'eyes' here\n",
        "# laneStability = ...\n",
        "# eyes = ...\n",
        "\n",
        "model = BayesianNetwork([(\"LengthOfDrive\", \"Fatigue\"),\n",
        "                         (\"TrafficJam\", \"Fatigue\"),\n",
        "                         (\"Fatigue\", \"HeartRate\"),\n",
        "                         (\"Fatigue\", \"LaneStability\"),\n",
        "                         (\"Eyes\", \"LaneStability\"),\n",
        "                         (\"Fatigue\", \"Eyes\")])\n",
        "\n",
        "model.add_cpds(lengthOfDrive, trafficJam, fatigue, heartRate, laneStability, eyes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6093rhQhE5"
      },
      "source": [
        "Az elkészült megoldást az előzőhöz hasonlóan egy *plot()* hívással tekinthetjük meg:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model)"
      ],
      "metadata": {
        "id": "9w_Zcnu0V2p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt7ERvoX6jVM"
      },
      "source": [
        "Hogyha a megoldás helyes, akkor a **LaneStability** és **Eyes** nevű csomópontok a **Fatigue** csomópont gyerekeiként szerepelnek, illetve a  **LaneStability** csomópont gyereke az **Eyes** csomópontnak is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qkD2fO5VNLV"
      },
      "source": [
        "## 2. feladat: Következtetés a modellben\n",
        "\n",
        "A valószínűségi hálókban végrehajtott következtetés során az ismeretlen változók lehetséges értékeinek valószínűségére vagyunk kíváncsiak, a már megfigyelt (és így ismert) változók értékeinek függvényében.\n",
        "\n",
        "A pgmpy keretrendszerben valamely következtető (esetünkben `VariableElimination`) [`query`](https://pgmpy.org/exact_infer/ve.html#pgmpy.inference.ExactInference.VariableElimination.query) függvényének segítségével hajthatunk végre következtetést, amelynél a már ismert változók értékét egy, azok nevével indexelt dictionary-ként adhatjuk meg, visszatérési értékként pedig a lekérdezett változók eloszlását kapjuk meg a megadott evidenciák függvényében.\n",
        "\n",
        "Kezdetben feltételezzük, hogy a változók egyike sem ismert. Ekkor a változók lehetséges értékeinek aktuális valószínűségét egy üres dictionary-vel végzett `query` hívással kérdezhetjük le, majd írassuk is ki az eredményt egy egyszerű `print`-hívás segítségével:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pgmpy.inference import VariableElimination\n",
        "inference = VariableElimination(model)\n",
        "\n",
        "evidence_set = {}\n",
        "\n",
        "query_result = inference.query(variables=[\"Fatigue\"],\n",
        "                               evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "0XBFzdB4PT4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_ZNM3oiRkbL"
      },
      "source": [
        "Az eredményből láthatjuk, hogy amennyiben nincs semmilyen előzetes tudásunk, akkor a fáradtság valószínűsége $0.42$.\n",
        "\n",
        "Tegyük fel, hogy a GPS szerint hosszú ideje úton van a sofőr, viszont a tervezett útvonalon nincs forgalmi dugó. Ekkor a lekérdezésben szereplő változó valószínűségét az alábbi módon kaphatjuk meg:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_set = {\"LengthOfDrive\": \"long\",\n",
        "                \"TrafficJam\":    \"clear\"}\n",
        "\n",
        "query_result = inference.query(variables=[\"Fatigue\"],\n",
        "                               evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "ToTxGRNJRFqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fewyham2Kg9t"
      },
      "source": [
        "Ezen eredményből megfigyelhetjük, hogy a fáradtság valószínűsége beállt a feltételes valószínűségi táblában a **LengthOfDrive**='*long*' és **TrafficJam**='*clear*' evidenciákhoz meghatározott $0.45$-ös értékre. Ez azonban nem jelenti azt, hogy a modell jelenleg ismeretlen változóinak evidenciaként történő bevezetése ne változtathatna a valószínűségén, Bayes-hálókban ugyanis egy változó a szüleinek ismeretében csak a nem-leszármazottaitól válik függetlenné, a maradék három csomópont pedig mind a **Fatigue** változónak leszármazottja.\n",
        "\n",
        "Feltételezzük, hogy a kormányban elhelyezett szenzor azt jelzi, hogy a sofőr pulzusa normális, nincs közel az alvás során mérhető értékhez. Ekkor a valószínűségek az alábbi módon alakulnak:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_set = {\"LengthOfDrive\": \"long\",\n",
        "                \"TrafficJam\":    \"clear\",\n",
        "                \"HeartRate\":     \"normal\"}\n",
        "\n",
        "query_result = inference.query(variables=[\"Fatigue\"],\n",
        "                               evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "2tf9TWh8RwW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHAYi9DxTWYB"
      },
      "source": [
        "Már a feltételes valószínűségi táblában meghatározott értékekből is látható, hogy a **HeartRate** viszonylag erősen korrelál a **Fatigue** változóval. Ebből adódóan nem meglepő, hogy a fáradtság valószínűségét ezen változó igazra állítása $0.45$-ről ~$0.19$-re csökkentette, ugyanis az erős evidenciának számít ezen változó '*normal*' értéke mellett.\n",
        "\n",
        "&#x1F4DD; Tegyük fel, hogy a vezető arcát néző kamera szerint a sofőr gyakran csukja be a szemét rövidebb időre.\n",
        "Módosítsa, majd futtassa le az alábbi kódblokkot úgy, hogy a meglévő három evidencia mellett a következtetés tartalmazza az **Eyes**='*blink*' evidenciát is:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Do the inference with the following values:\n",
        "#       - LengthOfDrive = long\n",
        "#       - TrafficJam = clear\n",
        "#       - HeartRate = normal\n",
        "#       - Eyes = blink\n",
        "\n",
        "# evidence_set = ...\n",
        "\n",
        "query_result = inference.query(variables=[\"Fatigue\"],\n",
        "                               evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "h3dbRwMoSIMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC-8ZSC7yjCS"
      },
      "source": [
        "Amennyiben a következtetést megfelelően hajtotta végre, úgy a **Fatigue** változó valószínűségeként ~$0.8$-at kellett kapjon. Ha figyelembe vesszük, hogy a feltételes valószínűségi tábla szerint fáradtság esetén a gyakori pislogás esélye $0.85$, míg fáradtság hiányában csupán $0.05$, akkor láthatjuk, hogy az **Eyes** változó még erősebb korrelációt mutat a fáradtsággal, mint a **HeartRate** változó. Ebből adódóan érthető, hogy a fáradtság valószínűségét ezen változó evidenciaként történő bevezetése ~$0.19$-ről ~$0.8$-ra növelte.\n",
        "\n",
        "&#x1F4DD; Végül pedig tegyük fel, hogy az autó külső kamerája szerint a sofőr elkezdte elhagyni a sávot. Vezesse be az alábbi kódblokkban az eddigi evidenciák mellé a **LaneStability**='*leaving*' értéket, majd futtassa le a blokkot:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Do the inference with the following values:\n",
        "#       - LengthOfDrive = long\n",
        "#       - TrafficJam = clear\n",
        "#       - HeartRate = normal\n",
        "#       - Eyes = blink\n",
        "#       - LaneStability = leaving\n",
        "\n",
        "# evidence_set = ...\n",
        "\n",
        "query_result = inference.query(variables=[\"Fatigue\"],\n",
        "                               evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "HsYiqy4qS6pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ul8vPAOP0t3h"
      },
      "source": [
        "Ha jól hajtotta végre a következtetést, akkor a fáradtság valószínűsége igen magas, ~$0.98$. Ha megnézzük a feltételes valószínűségi táblázatot, akkor láthatjuk, hogy a **LaneStability**='*leaving*' érték valószínűsége $0.1$ abban az esetben, hogyha a vezető fáradt ('*fatigued*') és gyakran pislog ('*blink*'), és $0.01$, hogyha a gyakori pislogás mellett nem fáradt ('*rested*'). Mivel tehát gyakori pislogás mellett a vezető fáradtsága esetén a sávelhagyás valószínűsége tízszerese annak, mint amikor nem fáradt, a sávelhagyás ténye erősen megnöveli a fáradtság a poszteriori valószínűségét, ~$0.8$-ról ~$0.98$-ra.\n",
        "\n",
        "&#x1F4DD; Ellenőrzésként vizsgálja meg azt a szituációt, amikor az autó külső kamerája szerint a sofőr egyenesen vezet (**LaneStability**='*straight*'). Ebben az esetben a fáradtság poszterior valószínűsége ~$0.8$-ról ~$0.76$-re csökken."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. feladat: Magyarázhatóság: a legvalószínűbb magyarázat meghatározása\n",
        "\n",
        "Az előbbiekben láthattuk, hogy hogyan lehet egy vagy több lekérdezési változó a poszteriori valószínűségét meghatározni a valószínűségi következtetés során. Lehetőség van azonban arra is, hogy a megfigyeléseink alapján meghatározzuk az összes többi, nem megfigyelt változó legvalószínűbb érték-konfigurációját. Egy orvosi döntéstámogatói esetben például arra keressük a választ, hogy az adott páciens tünetei alapján mi a lehetséges betegségek legvalószínűbb konfigurációja, azaz mely betegség(ek) fenállása magyarázza a megfigyelt tüneteket a lehető legnagyobb mértékben (mi a legvalószínűbb magyarázat).\n",
        "\n",
        "Az olyan tárgytartományok esetén, amelyekben több összefüggő célváltozó van, a többváltozós magyarázatok gyakran alkalmasabbak az adott bizonyítékok magyarázatára. A *maximum a posteriori hozzárendelés* (**Maximum a Posteriori Assignment** - MAP) során meghatározzuk a célváltozóknak azt a teljes érték-konfigurációját, amely maximalizálja az együttes eloszlást a részleges evidenciák figyelembevételével. A *legvalószínűbb magyarázat* (**Most Probable Explanation** - MPE) hasonló a MAP-hoz, azzal a kivétellel, hogy az MPE esetén a célváltozókat az összes nem megfigyelt változó definiálja.\n",
        "\n",
        "&#x1F4DD; Tegyük fel, hogy egy baleset során kell helyszínelnünk, és látjuk, hogy a vezető letért a sávról. (Egyelőre azonban semmi mást nem állapítottunk meg róla.)\n",
        "Határozzuk meg a legvalószínűbb szituációt (állapotot), amely a balesethez vezetett. Ehhez a `VariableElimination` osztály `map_query` függvényét kell használnunk. Határozzuk meg a legvalószínűbb állapot a poszteriori valószínűségét is, amelyet a `max_marginal` függvény segítségével tehetünk meg.\n"
      ],
      "metadata": {
        "id": "Va72cT4PcSoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evidence_set = {\"LaneStability\": \"leaving\", 'LengthOfDrive': 'long', 'TrafficJam': 'clear', \"Eyes\": \"open\" }\n",
        "################################################################################\n",
        "\n",
        "# A set of all variables in the model\n",
        "all_variables = {'LengthOfDrive','TrafficJam','HeartRate','Eyes','LaneStability','Fatigue'}\n",
        "# Find all other variables except our evidence variables\n",
        "other_variables = list(all_variables - set(evidence_set.keys()))\n",
        "\n",
        "# TODO: Do the MPE inference for the `other_variables` based on the `evidence_set`\n",
        "################################################################################\n",
        "# mpe_query_result =\n",
        "# mpe_query_probability =\n",
        "################################################################################\n",
        "\n",
        "print( f\"Most Probable Explanation: {mpe_query_result}\" )\n",
        "print( f\"Probability of MPE: {mpe_query_probability:.4f}\")"
      ],
      "metadata": {
        "id": "YEbRiTWwhAuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amennyiben jól dolgoztunk, a legvalószínűbb állapot az volt, hogy a vezető gyakran pislogott, a pulzusa alacsony volt, összességében fáradt volt, ugyanakkor rövid és forgalmi dugó mentes úton járt. Ennek az állapotnak a valószínűsége (a megfigyeléseink alapján) pedig ~$0.36$.\n",
        "\n",
        "Ellenőrizzük le a korábban már megismert egyszerű lekérdezéssel (`query`), hogy valóban ez volt-e a legvalószínűbb állapot. Ehhez futtassuk az alábbi kódblokkot, és keressük meg a legnagyobb valószínűségi értékkel rendelkezző bejegyzést."
      ],
      "metadata": {
        "id": "TkZsyavHUm2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = inference.query(variables=other_variables, evidence=evidence_set)\n",
        "print(query_result)"
      ],
      "metadata": {
        "id": "0GHSaJWNU3ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#x1F4DD; Tegyük fel, hogy a helyszínelés során kiderül, hogy a vezető hosszú ideje úton volt, de az út végig jól járható volt (azaz nem került dugóba). Hogyan befolyásolja ez az előző eredményeket, mennyire változik meg a legvalószínűbb állapot valószínűsége?\n",
        "\n",
        "&#x1F4DD; Végül tegyük fel, hogy a helyszínelés során az derül ki a szenzorok logjait visszanézve, hogy a szeme nyitva volt. Mi lesz ekkor a legvalószínűbb állapot, és mekkora annak valószínűsége? Vizsgáljuk meg, hogy a második legvalószínűbb állapot valószínűsége hogyan viszonyul a legvalószínűbbhöz!"
      ],
      "metadata": {
        "id": "ecj_8NciWWcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. feladat: Magyarázhatóság: szenzitivitásvizsgálat\n",
        "\n",
        "A valószínűségi hálóbeli következtetések során fontos információt szolgáltathat az, ha meg tudjuk állapítani, hogy bizonyos megfigyeléseket feltéve mely másik változókat lenne célszerű még megfigyelnünk ahhoz, hogy a célváltozó eloszlásáról biztosabb képet kaphassunk. Ebben segíthet például a következtetés információ-szenzitivitásának vizsgálata.\n",
        "\n",
        "Tegyük fel, hogy van a modellben egy célváltozó (halmaz), amelynek egy adott érték-konfigurációja érdekes számunkra (nevezzük ezt célértéknek). Jelölje ezt $T=t_i$. Ezen kívül rendelkezünk bizonyos megfigyelésekkel (természetesen ez lehet az üres halmaz is), jelölje ezt $E=e_j$, ahol $E$ egy változóhalmaz, $e_j$ pedig annak egy konkrét példányosítása (érték-konfigurációja). Rögzítsük ezután az összes többi, $K$ számú, nem megfigyelt változóknak egy sorrendjét, amely sorrend szerint vizsgálni szeretnénk azt, hogy hogyan befolyásolják ezek értékei a célváltozó célértékének valószínűségét.\n",
        "\n",
        "Az eljárásunk a következő lesz:\n",
        "* Kezdetben meghatározzuk a célváltozó célértékének feltételes valószínűségét a rendelkezésre álló megfigyelések alapján: $P(T=t_i|E=e_j)$.\n",
        "* Ezután a változóhalmaz fokozatos bővítésével a sorrend mentén ($k$ = 1-től $K$-ig):\n",
        " * Meghatározzuk a $V_{1:k}=\\{V_1,...,V_k\\}$ változóhalmaz lehetséges értékeinek a megfigyelésekkel vett feltételes valószínűségét: $P(V_{1:k}=v_l|E=e_j)$ minden lehetséges $v_l$ érték-konfigurációra, ahol $v_l$ a $V_{1:k}$ változóhalmaz minden egyes eleméhez rendel egy-egy konkrét értéket.\n",
        " * Majd minden lehetséges érték-konfigurációra meghatározzuk a célváltozó célértékének feltételes valószínűségét a kibővített evidenciákkal: $P(T=t_i|E=e_j,V_{1:k}=v_l)$.\n",
        " * Ezen értékeket feljegyezzük minden $v_l$ érték-konfigurációra.\n",
        "* Ábrázoljuk az eredményeket egy scatter ploton: az x-tengely mentén a fokozatosan bővített változóhalmazra vonatkozó eredményeket jelenítsük meg, az y-tengely mentén pedig a célváltozó célértékének valószínűsége legyen látható. A pontokat színezzük a változóhalmaz adott érték-konfigurációjának feltételes valószínűsége szerint.\n",
        "\n",
        "Az ábrázolásra használjuk az alábbi `plot_sensitivity_of_inference` függvényt. Ehhez futtassuk le a kódblokkot!"
      ],
      "metadata": {
        "id": "T5hPs1hocBPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def plot_sensitivity_of_inference( df : pd.DataFrame ):\n",
        "\n",
        "  # Create the hover text by formatting information from each column\n",
        "  df['hover_text'] = df.apply(lambda x: f\"<b>Target Probability:</b> {x['target_probability']:.4f}<br>\"\n",
        "                                        f\"<b>Evidence Probability:</b> {x['evidence_probability']:.4f}<br>\"\n",
        "                                        f\"<b>Evidence:</b> {str(x['extended_evidence'])}\",\n",
        "                              axis=1)\n",
        "\n",
        "  # Map normalized values to colors (white to blue)\n",
        "  df['colors'] = df['evidence_probability'].apply(lambda x: f'rgb({255 * (1-x)}, {255 * (1-x)}, 255)')\n",
        "\n",
        "  # Add jitter to var_index for clarity\n",
        "  jitter_strength = 0.05  # Adjust this to increase/decrease jitter\n",
        "  df['jittered_var_index'] = df['var_index'].astype(float) + (df['evidence_probability']-0.5)/4\n",
        "\n",
        "  # Creating the figure\n",
        "  fig = go.Figure()\n",
        "\n",
        "  # Adding the scatter plot\n",
        "  fig.add_trace(go.Scatter(x=df['jittered_var_index'], y=df['target_probability'],\n",
        "                          mode='markers',\n",
        "                          marker=dict(size=15, color=df['colors'], opacity=0.5, line=dict( color='gray', width=2 )),\n",
        "                          hoverinfo='text',\n",
        "                          text=df['hover_text']))\n",
        "\n",
        "  # Iterate over var_index values, except the last one\n",
        "  for i in df['var_index'].unique()[:-1]:\n",
        "      current_points = df[df['var_index'] == i]\n",
        "      next_points = df[df['var_index'] == i + 1]\n",
        "\n",
        "      # Compare each point in current_points with each point in next_points\n",
        "      for _, current_point in current_points.iterrows():\n",
        "          for _, next_point in next_points.iterrows():\n",
        "              # Check if extended_evidence of current is a subset of next\n",
        "              if set(current_point['extended_evidence'].items()).issubset(set(next_point['extended_evidence'].items())):\n",
        "                  # Add a line between these points\n",
        "                  fig.add_trace(go.Scatter(x=[current_point['jittered_var_index'], next_point['jittered_var_index']],\n",
        "                                          y=[current_point['target_probability'], next_point['target_probability']],\n",
        "                                          mode='lines',\n",
        "                                          line=dict(color='lightgray', width=1)))\n",
        "\n",
        "\n",
        "  # Customizing the layout\n",
        "  fig.update_layout(title='Sensitivity of inference',\n",
        "                    xaxis_title='Variable of additional evidence',\n",
        "                    yaxis_title='Target Probability',\n",
        "                    paper_bgcolor='white',\n",
        "                    plot_bgcolor='white',\n",
        "                    xaxis=dict( showgrid=True, gridcolor='gray', gridwidth=1, zeroline=True, zerolinecolor='gray' ),\n",
        "                    yaxis=dict( showgrid=True, gridcolor='gray', gridwidth=1, zeroline=True, zerolinecolor='gray' ),\n",
        "                    height = 600,\n",
        "                    showlegend = False)\n",
        "\n",
        "  # Update x-axis ticks to match original 'var_index' categories if needed\n",
        "  fig.update_xaxes(tickvals=df['var_index'].unique(), ticktext=df['variable'].unique())\n",
        "\n",
        "  fig.show()"
      ],
      "metadata": {
        "id": "aOWCICm821Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#x1F4DD; Értelmezzük az alábbi kódot!"
      ],
      "metadata": {
        "id": "OL_knfCZq8-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_sensitivity_of_inference( evidence_set, target_set, variables ):\n",
        "  \"\"\"\n",
        "  This function calculates the sensitivity of inference for a given target\n",
        "  and for an iteratively increased set of variables, given a set of evidences.\n",
        "  \"\"\"\n",
        "  # Create an empty list for the results\n",
        "  entries = []\n",
        "\n",
        "  # 1.a. Query P(T=t_i|E=e_j)\n",
        "  query_target = inference.query( variables=[k for k in target_set.keys()], evidence=evidence_set)\n",
        "  target_probability = query_target.get_value( **target_set )\n",
        "\n",
        "  # 1.b. Query P(E=e_j)\n",
        "  query_evidence = inference.query( variables=[k for k in evidence_set.keys()] )\n",
        "  evidence_probability = query_evidence.get_value( **evidence_set )\n",
        "\n",
        "  # 1.c. Append the results into the entries list as a dictionary\n",
        "  entries.append( { \"var_index\": 0,\n",
        "                    \"variable\": str([k for k in evidence_set.keys()]),\n",
        "                    \"target_probability\": target_probability,\n",
        "                    \"evidence_probability\": evidence_probability,\n",
        "                    \"extended_evidence\": evidence_set } )\n",
        "\n",
        "  # 2. Iterate over all variables in the given ordering\n",
        "  for var_index in range(len(variables)):\n",
        "\n",
        "    # 2.a. Calculate the conditional probability of every possible instatinations of the new evidence variables:  P(V_{1:k}|E=e_j)\n",
        "    posterior_of_new_evidence_based_on_current_evidence = inference.query( variables=variables[:(var_index+1)], evidence=evidence_set )\n",
        "\n",
        "    # 2.b. Calculate the size of the different instantiations of the new evidence variables\n",
        "    cardinalities = posterior_of_new_evidence_based_on_current_evidence.get_cardinality(variables[:(var_index+1)])\n",
        "    max_index = np.prod( [c for _,c in cardinalities.items()] )\n",
        "\n",
        "    # 2.c. Iterate over the different instantiations of the new evidence variables\n",
        "    for index in range(0,max_index):\n",
        "      # 1. Get the appropriate variable instantiation: v_l\n",
        "      new_evidence_instantiation = posterior_of_new_evidence_based_on_current_evidence.assignment([index])[0]\n",
        "      new_evidence_instantiation_as_dict = {var:state for var,state in new_evidence_instantiation}\n",
        "\n",
        "      # 2. Get the probability of the appropriate variable instantiation: P(V_{1:k}=v_l|E=e_j)\n",
        "      probability_of_new_evidence_instantiation_based_on_current_evidence = posterior_of_new_evidence_based_on_current_evidence.get_value( **new_evidence_instantiation_as_dict )\n",
        "\n",
        "      # 3. Extend the set of the known evidences: {E=e_j, V_{1:k}=v_l}\n",
        "      extended_evidence_set = { **evidence_set, **new_evidence_instantiation_as_dict }\n",
        "\n",
        "      # 4. Compute the posterior probability of the *target variable* based on the extended set of evidences: P(T=t_i|E=e_j,V_{1:k}=v_l)\n",
        "      posterior_of_target_based_on_extended_evidence = inference.query( variables = [k for k in target_set.keys()], evidence = extended_evidence_set )\n",
        "      target_probability = posterior_of_target_based_on_extended_evidence.get_value( **target_set )\n",
        "\n",
        "      # 5. Append the results into the entries list as a dictionary\n",
        "      entries.append( { \"var_index\": var_index+1,\n",
        "                        \"variable\": variables[var_index],\n",
        "                        \"target_probability\": target_probability,\n",
        "                        \"evidence_probability\": probability_of_new_evidence_instantiation_based_on_current_evidence,\n",
        "                        \"extended_evidence\": extended_evidence_set } )\n",
        "\n",
        "  # 3. Create a dataframe\n",
        "  df = pd.DataFrame(entries)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "RG9-EcQTcKsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Induljunk ki az alábbi beállításokból:\n",
        "\n",
        "Kezdetben nincs megfigyelésünk, a célváltozó a fáradtság (**Fatigue**), és a célérték ennek *fatigued* értéke.\n",
        "A változósorrend pedig legyen `['Eyes','HeartRate','LaneStability','TrafficJam','LengthOfDrive']`."
      ],
      "metadata": {
        "id": "HcNsOyFvrkNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial evidences\n",
        "evidence_set = {}\n",
        "# Target variable and its target value\n",
        "target_set = {'Fatigue': 'fatigued'}\n",
        "# Other variables in a specified order\n",
        "variables = ['Eyes','HeartRate','LaneStability','LengthOfDrive','TrafficJam']"
      ],
      "metadata": {
        "id": "LcfMrFqwrhIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Futassuk le a számítást és vizualizálást az alábbi kódblokk végrehajtásával!"
      ],
      "metadata": {
        "id": "DEk9z79X5Jn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate the sensitivity of inference\n",
        "df = calculate_sensitivity_of_inference( evidence_set, target_set, variables )\n",
        "# 2. Visualize the results\n",
        "plot_sensitivity_of_inference( df )"
      ],
      "metadata": {
        "id": "_8vJUsaU43dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&#x1F4DD; Értelmezzük a kapott eredményeket!\n",
        "\n",
        "&#x1F4DD; Próbálkozzunk más változósorrendekkel is! Melyik változó befolyásolja leginkább a célváltozó értékét? Melyik további változó megfigyelése tudná leginkább csökkenteni a célváltozó eloszlásának bizonytalanságát?\n",
        "\n",
        "&#x1F4DD; Tegyük fel, hogy a szemeket figyelő szenzor értékét megfigyelve azt látjuk, hogy a vezető szemei csukva vannak (*closed*). Vegyük fel ezt evidenciaként, és keressünk egy informatív sorrendet a többi változóhoz!"
      ],
      "metadata": {
        "id": "Bi5gOHEa5U1C"
      }
    }
  ]
}